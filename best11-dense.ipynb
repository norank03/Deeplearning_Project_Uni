{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":46697,"sourceType":"datasetVersion","datasetId":31559}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Path to the training images\ntrain_images_dir = '/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/train'\nimage_size=224\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255, \n    validation_split=0.2, \n    shear_range=0.2,\n    zoom_range=0.2,  \n    horizontal_flip=True,  \n    brightness_range=[0.8, 1.2], \n    rotation_range=15,  \n    width_shift_range=0.2,  \n    height_shift_range=0.2, \n    fill_mode='nearest',  \n    channel_shift_range=5.0,  \n)\n\n\n# Create the training generator for training data\ntrain_generator = train_datagen.flow_from_directory(\n    train_images_dir,  # Path to the training images\n    target_size=(image_size, image_size),  # Resize images to target size (set image_size beforehand)\n    batch_size=32,  # Number of images to process in each batch\n    class_mode='categorical',  # For multi-class classification\n    subset='training',  # Set subset to 'training' for training data\n        shuffle=True,  # Shuffle data after each epoch\n)\n\n# Create the validation generator\nvalidation_generator = train_datagen.flow_from_directory(\n    train_images_dir,  # Path to the training images\n    target_size=(image_size, image_size),  # Resize images to target size (set image_size beforehand)\n    batch_size=32,  # Number of images to process in each batch\n    class_mode='categorical',  # For multi-class classification\n    subset='validation',  # Set subset to 'validation' for validation data\n    shuffle=False,  # Don't shuffle validation data\n)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-17T23:09:48.516069Z","iopub.execute_input":"2024-12-17T23:09:48.516450Z","iopub.status.idle":"2024-12-17T23:09:53.793064Z","shell.execute_reply.started":"2024-12-17T23:09:48.516419Z","shell.execute_reply":"2024-12-17T23:09:53.792132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers, callbacks\nimport os\n\n# Required constants\nimage_size = 224  # Image size (224x224 is the default input size for DenseNet)\nbatch_size = 32\nepochs = 55\nnum_classes = 196  # Number of classes for classification (replace with actual number of classes)\nlearning_rate = 0.01\n\n# Load pre-trained DenseNet121 model (without the top layers)\nbase_model = tf.keras.applications.DenseNet121(\n    include_top=False,  # Exclude the fully connected layers at the top\n    weights='imagenet',  # Use ImageNet weights\n    input_shape=(image_size, image_size, 3)  # Input size (224x224x3)\n)\n\n# Freeze the layers in DenseNet to avoid retraining them\nbase_model.trainable = False\n\n# Build the full model with custom classification head\nmodel = models.Sequential([\n    base_model,  # Add DenseNet backbone as base\n    layers.GlobalAveragePooling2D(),  # Global average pooling to reduce the spatial dimensions\n    layers.Dense(4096, activation='relu'),  # Dense layer (1024 units)\n    #layers.Dense(320, activation='relu'),  # Dense layer (320 units)\n    layers.Dropout(0.5),  # Dropout with 50% probability\n    layers.Dense(num_classes, activation='softmax')  # Final classification layer (output layer)\n])\noptimizer = optimizers.Adam(learning_rate=0.001)  # Default learning rate for Adam\n\nfor layer in base_model.layers[-20:]:\n    layer.trainable = True\n    \nmodel.compile(optimizer=optimizer, \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])\n\nhistory = model.fit(\n    train_generator,  # Assuming you have 'train_generator' from ImageDataGenerator\n    epochs=epochs,\n    validation_data=validation_generator,  # Assuming you have 'validation_generator'\n    steps_per_epoch=train_generator.samples // batch_size,  # Number of batches per epoch\n    validation_steps=validation_generator.samples // batch_size,  # Number of validation steps\n    #callbacks=[ checkpoint_callback]  # Include the callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T23:09:53.794782Z","iopub.execute_input":"2024-12-17T23:09:53.795277Z","iopub.status.idle":"2024-12-18T00:09:59.727299Z","shell.execute_reply.started":"2024-12-17T23:09:53.795247Z","shell.execute_reply":"2024-12-18T00:09:59.726481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dir = '/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/test'\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(image_size, image_size),\n    batch_size=batch_size,\n    class_mode='categorical',  # For multi-class classification\n    shuffle=False  # Don't shuffle test data\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T00:09:59.729564Z","iopub.execute_input":"2024-12-18T00:09:59.730648Z","iopub.status.idle":"2024-12-18T00:10:05.185665Z","shell.execute_reply.started":"2024-12-18T00:09:59.730600Z","shell.execute_reply":"2024-12-18T00:10:05.184646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on the test data\ntest_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\nprint(f'Test Loss: {test_loss}')\nprint(f'Test Accuracy: {test_acc}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T00:10:05.187040Z","iopub.execute_input":"2024-12-18T00:10:05.187335Z","iopub.status.idle":"2024-12-18T00:10:47.575240Z","shell.execute_reply.started":"2024-12-18T00:10:05.187305Z","shell.execute_reply":"2024-12-18T00:10:47.574245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(12, 4))\n\n# Accuracy Curve\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss Curve\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T00:12:09.949678Z","iopub.execute_input":"2024-12-18T00:12:09.950101Z","iopub.status.idle":"2024-12-18T00:12:10.398740Z","shell.execute_reply.started":"2024-12-18T00:12:09.950067Z","shell.execute_reply":"2024-12-18T00:12:10.397770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Get Ground Truth Labels and Predictions\nY_true = validation_generator.classes  # Ground truth\nY_pred = model.predict(validation_generator)\nY_pred_classes = np.argmax(Y_pred, axis=1)\n\n# Compute Confusion Matrix\ncm = confusion_matrix(Y_true, Y_pred_classes)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=validation_generator.class_indices.keys())\n\n# Visualize Confusion Matrix\nplt.figure(figsize=(8, 6))\ndisp.plot(cmap=plt.cm.Blues)\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T00:12:11.793558Z","iopub.execute_input":"2024-12-18T00:12:11.793981Z","iopub.status.idle":"2024-12-18T00:13:45.886332Z","shell.execute_reply.started":"2024-12-18T00:12:11.793909Z","shell.execute_reply":"2024-12-18T00:13:45.885340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Get Ground Truth Labels and Predictions\nY_true = validation_generator.classes  # Ground truth\nY_pred = model.predict(validation_generator)\nY_pred_classes = np.argmax(Y_pred, axis=1)\n\n# Compute Confusion Matrix\ncm = confusion_matrix(Y_true, Y_pred_classes)\n\n# Sum of misclassifications per class\nmisclassifications = np.sum(cm, axis=1) - np.diag(cm)\n\n# Select Top-K Classes with Most Misclassifications\nK = 10\ntop_k_classes = np.argsort(misclassifications)[-K:]\n\n# Create Reduced Confusion Matrix\ncm_reduced = cm[np.ix_(top_k_classes, top_k_classes)]\nclass_labels = np.array(list(validation_generator.class_indices.keys()))[top_k_classes]\n\n# Display Reduced Confusion Matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm_reduced, display_labels=class_labels)\n\nplt.figure(figsize=(8, 6))\ndisp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\nplt.title(f\"Top-{K} Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T00:13:45.888292Z","iopub.execute_input":"2024-12-18T00:13:45.889550Z","iopub.status.idle":"2024-12-18T00:14:12.567418Z","shell.execute_reply.started":"2024-12-18T00:13:45.889501Z","shell.execute_reply":"2024-12-18T00:14:12.566455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate Classification Report\nprint(\"Classification Report:\\n\")\nreport = classification_report(Y_true, Y_pred_classes, target_names=validation_generator.class_indices.keys())\nprint(report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T00:14:12.568725Z","iopub.execute_input":"2024-12-18T00:14:12.569024Z","iopub.status.idle":"2024-12-18T00:14:12.590604Z","shell.execute_reply.started":"2024-12-18T00:14:12.568995Z","shell.execute_reply":"2024-12-18T00:14:12.589614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\n# Binarize the labels for multi-class ROC\nn_classes = len(validation_generator.class_indices)\nY_true_bin = label_binarize(Y_true, classes=[i for i in range(n_classes)])\n\n# Compute ROC curve and AUC for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_true_bin[:, i], Y_pred[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curves\nplt.figure(figsize=(10, 7))\nfor i in range(n_classes):\n    plt.plot(fpr[i], tpr[i], label=f\"Class {i} (AUC = {roc_auc[i]:.2f})\")\n\nplt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curves for Multi-Class Classification\")\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T00:14:12.592517Z","iopub.execute_input":"2024-12-18T00:14:12.592823Z","iopub.status.idle":"2024-12-18T00:14:14.834119Z","shell.execute_reply.started":"2024-12-18T00:14:12.592795Z","shell.execute_reply":"2024-12-18T00:14:14.833224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}